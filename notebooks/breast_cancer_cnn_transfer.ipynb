{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4579656",
   "metadata": {},
   "source": [
    "# Breast Cancer Classification using 1D CNN + Transfer Learning (Autoencoder)\n",
    "\n",
    "This notebook:\n",
    "1. Loads the WDBC dataset (Kaggle CSV if available; otherwise falls back to `sklearn`).\n",
    "2. Preprocesses features and labels.\n",
    "3. Trains classic ML baselines.\n",
    "4. Trains an **autoencoder** on the features, then **transfers** the encoder to a 1D CNN classifier.\n",
    "5. Evaluates with confusion matrix, ROC/PR, and classification report.\n",
    "\n",
    "> _Dataset columns example (as you showed): `id`, `diagnosis`, 30 numeric features, and an all-NaN `Unnamed: 32`._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ccf4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Versions & reproducibility\n",
    "import sys, numpy as np, random, tensorflow as tf, sklearn, pandas as pd, matplotlib\n",
    "print(\"Python\", sys.version.split()[0])\n",
    "print(\"NumPy\", np.__version__)\n",
    "print(\"Pandas\", pd.__version__)\n",
    "print(\"Scikit-learn\", sklearn.__version__)\n",
    "print(\"TensorFlow\", tf.__version__)\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed); np.random.seed(seed); tf.random.set_seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea57a2d",
   "metadata": {},
   "source": [
    "## 1) Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6b1a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from src.utils import load_wdbc_csv_or_sklearn, preprocess\n",
    "\n",
    "DATA_PATH = Path('../data/data.csv')\n",
    "df = load_wdbc_csv_or_sklearn(str(DATA_PATH))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85d2f4a",
   "metadata": {},
   "source": [
    "## 2) Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe4265",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = preprocess(df)\n",
    "X.shape, y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3d915d",
   "metadata": {},
   "source": [
    "## 3) Train/Val/Test split + scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cdc8d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.3, stratify=y, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_s = scaler.fit_transform(X_train)\n",
    "X_val_s = scaler.transform(X_val)\n",
    "X_test_s = scaler.transform(X_test)\n",
    "\n",
    "X_train_c = X_train_s[..., None]\n",
    "X_val_c = X_val_s[..., None]\n",
    "X_test_c = X_test_s[..., None]\n",
    "\n",
    "classes = np.unique(y_train)\n",
    "class_weights = dict(zip(\n",
    "    classes,\n",
    "    compute_class_weight(class_weight=\"balanced\", classes=classes, y=y_train)\n",
    "))\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb6c9ec",
   "metadata": {},
   "source": [
    "## 4) Baselines (LogReg, RandomForest, GradientBoosting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd62c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "models = {\n",
    "    \"LogReg\": LogisticRegression(max_iter=500, n_jobs=None),\n",
    "    \"RF\": RandomForestClassifier(n_estimators=400, random_state=42),\n",
    "    \"GB\": GradientBoostingClassifier(random_state=42),\n",
    "}\n",
    "\n",
    "for name, mdl in models.items():\n",
    "    mdl.fit(X_train_s, y_train)\n",
    "    proba = mdl.predict_proba(X_val_s)[:,1]\n",
    "    auc = roc_auc_score(y_val, proba)\n",
    "    print(f\"{name}: Val ROC-AUC = {auc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9e29e4",
   "metadata": {},
   "source": [
    "## 5) Autoencoder pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94415d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import build_autoencoder\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "ae, enc = build_autoencoder(X_train_c.shape[1], latent_dim=16)\n",
    "cb = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_loss\")]\n",
    "hist = ae.fit(X_train_c, X_train_c, validation_data=(X_val_c, X_val_c),\n",
    "              epochs=60, batch_size=32, verbose=2, callbacks=cb)\n",
    "\n",
    "# Plot loss\n",
    "plt.figure()\n",
    "plt.plot(hist.history['loss'], label='train_loss')\n",
    "plt.plot(hist.history['val_loss'], label='val_loss')\n",
    "plt.legend(); plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.title('Autoencoder Training Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e109c85b",
   "metadata": {},
   "source": [
    "## 6) Transfer encoder to CNN classifier (frozen â†’ fine-tuned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da614e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models import build_cnn_classifier\n",
    "\n",
    "# Frozen encoder\n",
    "clf = build_cnn_classifier(X_train_c.shape[1], encoder=enc, freeze_encoder=True)\n",
    "cb = [keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True, monitor=\"val_auc\", mode=\"max\")]\n",
    "hist = clf.fit(X_train_c, y_train, validation_data=(X_val_c, y_val),\n",
    "               epochs=60, batch_size=32, verbose=2, class_weight=class_weights, callbacks=cb)\n",
    "\n",
    "# Fine-tune: unfreeze\n",
    "for layer in clf.layers:\n",
    "    layer.trainable = True\n",
    "clf.compile(optimizer=keras.optimizers.Adam(1e-4), loss='binary_crossentropy',\n",
    "            metrics=[keras.metrics.AUC(name='auc'), 'accuracy'])\n",
    "hist_ft = clf.fit(X_train_c, y_train, validation_data=(X_val_c, y_val),\n",
    "                  epochs=30, batch_size=32, verbose=2, class_weight=class_weights, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13212d3a",
   "metadata": {},
   "source": [
    "## 7) Evaluation on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da2bc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, precision_recall_curve, average_precision_score\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_proba = clf.predict(X_test_c).ravel()\n",
    "y_pred = (y_proba >= 0.5).astype(int)\n",
    "\n",
    "print(classification_report(y_test, y_pred, digits=4))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "cm\n",
    "\n",
    "# ROC\n",
    "fpr, tpr, _ = roc_curve(y_test, y_proba)\n",
    "plt.figure(); plt.plot(fpr, tpr); plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate'); plt.title('ROC Curve'); plt.show()\n",
    "\n",
    "# PR\n",
    "prec, rec, _ = precision_recall_curve(y_test, y_proba)\n",
    "ap = average_precision_score(y_test, y_proba)\n",
    "plt.figure(); plt.plot(rec, prec)\n",
    "plt.xlabel('Recall'); plt.ylabel('Precision'); plt.title(f'Precision-Recall Curve (AP={ap:.3f})'); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f84062",
   "metadata": {},
   "source": [
    "## 8) Save artifacts & simple inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2541b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "outdir = Path('../outputs')\n",
    "outdir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save model & scaler\n",
    "clf.save(outdir / 'cnn_finetuned.keras')\n",
    "joblib.dump(scaler, outdir / 'scaler.joblib')\n",
    "\n",
    "# Inference example\n",
    "import numpy as np\n",
    "sample = X_test.iloc[[0]].to_numpy()\n",
    "sample_s = scaler.transform(sample)[..., None]\n",
    "proba = clf.predict(sample_s).ravel()[0]\n",
    "print(\"Sample probability of malignancy:\", float(proba))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
